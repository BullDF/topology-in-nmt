{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore TDA-BLEU Correlation\n",
    "\n",
    "Combine topological similarity (Wasserstein distance) with translation quality (BLEU scores) to test our hypothesis:\n",
    "\n",
    "**Does topological similarity between English and French attention patterns predict translation quality?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load TDA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TDA results\n",
    "tda_path = Path(\"../data/tda_results/tda_results_last_layer_filtered.pkl\")\n",
    "\n",
    "print(f\"Loading TDA results from {tda_path}...\")\n",
    "with open(tda_path, 'rb') as f:\n",
    "    tda_results = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Loaded {len(tda_results)} TDA results\")\n",
    "\n",
    "# Extract relevant TDA metrics\n",
    "df_tda = pd.DataFrame([{\n",
    "    'idx': r['idx'],\n",
    "    'wasserstein_distance': r['wasserstein_distance'],\n",
    "    'wasserstein_h0': r['wasserstein_h0'],\n",
    "    'wasserstein_h1': r['wasserstein_h1'],\n",
    "    'en_num_tokens': r['en_num_tokens'],\n",
    "    'fr_num_tokens': r['fr_num_tokens'],\n",
    "    'en_h0_features': r['en_h0_features'],\n",
    "    'en_h1_features': r['en_h1_features'],\n",
    "    'fr_h0_features': r['fr_h0_features'],\n",
    "    'fr_h1_features': r['fr_h1_features']\n",
    "} for r in tda_results])\n",
    "\n",
    "print(f\"\\nTDA DataFrame shape: {df_tda.shape}\")\n",
    "print(df_tda.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load BLEU Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BLEU scores\n",
    "bleu_path = Path(\"../data/bleu_scores.csv\")\n",
    "\n",
    "print(f\"Loading BLEU scores from {bleu_path}...\")\n",
    "df_bleu = pd.read_csv(bleu_path)\n",
    "\n",
    "print(f\"✓ Loaded {len(df_bleu)} BLEU scores\")\n",
    "print(f\"\\nBLEU DataFrame shape: {df_bleu.shape}\")\n",
    "print(df_bleu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on idx\n",
    "df = pd.merge(df_tda, df_bleu, on='idx')\n",
    "\n",
    "print(f\"✓ Merged DataFrame shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "print(\"Wasserstein Distance:\")\n",
    "print(f\"  Mean: {df['wasserstein_distance'].mean():.6f}\")\n",
    "print(f\"  Std:  {df['wasserstein_distance'].std():.6f}\")\n",
    "print()\n",
    "\n",
    "print(\"BLEU Scores:\")\n",
    "print(f\"  EN→FR - Mean: {df['bleu_en_fr'].mean():.2f}, Std: {df['bleu_en_fr'].std():.2f}\")\n",
    "print(f\"  FR→EN - Mean: {df['bleu_fr_en'].mean():.2f}, Std: {df['bleu_fr_en'].std():.2f}\")\n",
    "print(f\"  Avg   - Mean: {df['bleu_avg'].mean():.2f}, Std: {df['bleu_avg'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlations between Wasserstein distance and BLEU scores\n",
    "print(\"=\" * 70)\n",
    "print(\"CORRELATION ANALYSIS: Wasserstein Distance vs BLEU\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Pearson correlation (linear relationship)\n",
    "pearson_en_fr, p_pearson_en_fr = pearsonr(df['wasserstein_distance'], df['bleu_en_fr'])\n",
    "pearson_fr_en, p_pearson_fr_en = pearsonr(df['wasserstein_distance'], df['bleu_fr_en'])\n",
    "pearson_avg, p_pearson_avg = pearsonr(df['wasserstein_distance'], df['bleu_avg'])\n",
    "\n",
    "print(\"Pearson Correlation (linear):\")\n",
    "print(f\"  Wasserstein vs EN→FR BLEU: r = {pearson_en_fr:.4f}, p = {p_pearson_en_fr:.2e}\")\n",
    "print(f\"  Wasserstein vs FR→EN BLEU: r = {pearson_fr_en:.4f}, p = {p_pearson_fr_en:.2e}\")\n",
    "print(f\"  Wasserstein vs Avg BLEU:   r = {pearson_avg:.4f}, p = {p_pearson_avg:.2e}\")\n",
    "print()\n",
    "\n",
    "# Spearman correlation (monotonic relationship)\n",
    "spearman_en_fr, p_spearman_en_fr = spearmanr(df['wasserstein_distance'], df['bleu_en_fr'])\n",
    "spearman_fr_en, p_spearman_fr_en = spearmanr(df['wasserstein_distance'], df['bleu_fr_en'])\n",
    "spearman_avg, p_spearman_avg = spearmanr(df['wasserstein_distance'], df['bleu_avg'])\n",
    "\n",
    "print(\"Spearman Correlation (monotonic):\")\n",
    "print(f\"  Wasserstein vs EN→FR BLEU: ρ = {spearman_en_fr:.4f}, p = {p_spearman_en_fr:.2e}\")\n",
    "print(f\"  Wasserstein vs FR→EN BLEU: ρ = {spearman_fr_en:.4f}, p = {p_spearman_fr_en:.2e}\")\n",
    "print(f\"  Wasserstein vs Avg BLEU:   ρ = {spearman_avg:.4f}, p = {p_spearman_avg:.2e}\")\n",
    "print()\n",
    "\n",
    "# Interpretation\n",
    "print(\"Interpretation:\")\n",
    "if abs(pearson_avg) < 0.1:\n",
    "    strength = \"negligible\"\n",
    "elif abs(pearson_avg) < 0.3:\n",
    "    strength = \"weak\"\n",
    "elif abs(pearson_avg) < 0.5:\n",
    "    strength = \"moderate\"\n",
    "else:\n",
    "    strength = \"strong\"\n",
    "\n",
    "direction = \"negative\" if pearson_avg < 0 else \"positive\"\n",
    "print(f\"  Overall correlation is {strength} and {direction}.\")\n",
    "\n",
    "if pearson_avg < 0:\n",
    "    print(f\"  → Lower Wasserstein distance (more similar topology) is associated with higher BLEU (better translation).\")\n",
    "else:\n",
    "    print(f\"  → Higher Wasserstein distance (more different topology) is associated with higher BLEU (better translation).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Scatter Plots: Wasserstein Distance vs BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# EN→FR BLEU\n",
    "axes[0].scatter(df['wasserstein_distance'], df['bleu_en_fr'], alpha=0.3, s=10)\n",
    "axes[0].set_xlabel('Wasserstein Distance\\n(Lower = More Topologically Similar)')\n",
    "axes[0].set_ylabel('EN→FR BLEU Score')\n",
    "axes[0].set_title(f'Wasserstein vs EN→FR BLEU\\nr = {pearson_en_fr:.3f}, p = {p_pearson_en_fr:.2e}')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df['wasserstein_distance'], df['bleu_en_fr'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[0].plot(df['wasserstein_distance'], p(df['wasserstein_distance']), \"r--\", alpha=0.5, label='Trend')\n",
    "axes[0].legend()\n",
    "\n",
    "# FR→EN BLEU\n",
    "axes[1].scatter(df['wasserstein_distance'], df['bleu_fr_en'], alpha=0.3, s=10)\n",
    "axes[1].set_xlabel('Wasserstein Distance\\n(Lower = More Topologically Similar)')\n",
    "axes[1].set_ylabel('FR→EN BLEU Score')\n",
    "axes[1].set_title(f'Wasserstein vs FR→EN BLEU\\nr = {pearson_fr_en:.3f}, p = {p_pearson_fr_en:.2e}')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "z = np.polyfit(df['wasserstein_distance'], df['bleu_fr_en'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1].plot(df['wasserstein_distance'], p(df['wasserstein_distance']), \"r--\", alpha=0.5, label='Trend')\n",
    "axes[1].legend()\n",
    "\n",
    "# Average BLEU\n",
    "axes[2].scatter(df['wasserstein_distance'], df['bleu_avg'], alpha=0.3, s=10)\n",
    "axes[2].set_xlabel('Wasserstein Distance\\n(Lower = More Topologically Similar)')\n",
    "axes[2].set_ylabel('Average BLEU Score')\n",
    "axes[2].set_title(f'Wasserstein vs Average BLEU\\nr = {pearson_avg:.3f}, p = {p_pearson_avg:.2e}')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "z = np.polyfit(df['wasserstein_distance'], df['bleu_avg'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[2].plot(df['wasserstein_distance'], p(df['wasserstein_distance']), \"r--\", alpha=0.5, label='Trend')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. H0 vs H1 Contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze H0 and H1 components separately\n",
    "print(\"=\" * 70)\n",
    "print(\"H0 vs H1 CONTRIBUTION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# H0 correlations\n",
    "pearson_h0, p_h0 = pearsonr(df['wasserstein_h0'], df['bleu_avg'])\n",
    "print(f\"H0 (Connected Components) vs Avg BLEU:\")\n",
    "print(f\"  Pearson r = {pearson_h0:.4f}, p = {p_h0:.2e}\")\n",
    "print()\n",
    "\n",
    "# H1 correlations\n",
    "pearson_h1, p_h1 = pearsonr(df['wasserstein_h1'], df['bleu_avg'])\n",
    "print(f\"H1 (Loops/Holes) vs Avg BLEU:\")\n",
    "print(f\"  Pearson r = {pearson_h1:.4f}, p = {p_h1:.2e}\")\n",
    "print()\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].scatter(df['wasserstein_h0'], df['bleu_avg'], alpha=0.3, s=10)\n",
    "axes[0].set_xlabel('H0 Wasserstein Distance')\n",
    "axes[0].set_ylabel('Average BLEU Score')\n",
    "axes[0].set_title(f'H0 vs BLEU\\nr = {pearson_h0:.3f}, p = {p_h0:.2e}')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "z = np.polyfit(df['wasserstein_h0'], df['bleu_avg'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[0].plot(df['wasserstein_h0'], p(df['wasserstein_h0']), \"r--\", alpha=0.5)\n",
    "\n",
    "axes[1].scatter(df['wasserstein_h1'], df['bleu_avg'], alpha=0.3, s=10)\n",
    "axes[1].set_xlabel('H1 Wasserstein Distance')\n",
    "axes[1].set_ylabel('Average BLEU Score')\n",
    "axes[1].set_title(f'H1 vs BLEU\\nr = {pearson_h1:.3f}, p = {p_h1:.2e}')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "z = np.polyfit(df['wasserstein_h1'], df['bleu_avg'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1].plot(df['wasserstein_h1'], p(df['wasserstein_h1']), \"r--\", alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Binned Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin by Wasserstein distance and compare mean BLEU scores\n",
    "df['w_bin'] = pd.qcut(df['wasserstein_distance'], q=5, labels=['Very Similar', 'Similar', 'Moderate', 'Dissimilar', 'Very Dissimilar'])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BINNED ANALYSIS: Mean BLEU by Topological Similarity\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "binned_stats = df.groupby('w_bin').agg({\n",
    "    'bleu_avg': ['mean', 'std', 'count'],\n",
    "    'wasserstein_distance': ['mean', 'std']\n",
    "})\n",
    "\n",
    "print(binned_stats)\n",
    "print()\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bin_means = df.groupby('w_bin')['bleu_avg'].mean()\n",
    "bin_stds = df.groupby('w_bin')['bleu_avg'].std()\n",
    "\n",
    "ax.bar(range(len(bin_means)), bin_means, yerr=bin_stds, capsize=5, alpha=0.7, edgecolor='black')\n",
    "ax.set_xticks(range(len(bin_means)))\n",
    "ax.set_xticklabels(bin_means.index, rotation=45, ha='right')\n",
    "ax.set_xlabel('Topological Similarity (Wasserstein Distance Bins)')\n",
    "ax.set_ylabel('Mean BLEU Score')\n",
    "ax.set_title('Translation Quality by Topological Similarity')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Examples: High Similarity vs Low Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Wasserstein distance\n",
    "df_sorted = df.sort_values('wasserstein_distance')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"HIGH TOPOLOGICAL SIMILARITY (Low Wasserstein Distance)\")\n",
    "print(\"=\" * 70)\n",
    "for i in range(5):\n",
    "    row = df_sorted.iloc[i]\n",
    "    print(f\"\\n[{i+1}] Pair {int(row['idx'])}: W = {row['wasserstein_distance']:.4f}, BLEU = {row['bleu_avg']:.2f}\")\n",
    "    \n",
    "    # Get original text from TDA results\n",
    "    original = tda_results[int(row['idx'])]\n",
    "    print(f\"    EN: {original['en_text']}\")\n",
    "    print(f\"    FR: {original['fr_text']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LOW TOPOLOGICAL SIMILARITY (High Wasserstein Distance)\")\n",
    "print(\"=\" * 70)\n",
    "for i in range(5):\n",
    "    row = df_sorted.iloc[-(i+1)]\n",
    "    print(f\"\\n[{i+1}] Pair {int(row['idx'])}: W = {row['wasserstein_distance']:.4f}, BLEU = {row['bleu_avg']:.2f}\")\n",
    "    \n",
    "    original = tda_results[int(row['idx'])]\n",
    "    print(f\"    EN: {original['en_text']}\")\n",
    "    print(f\"    FR: {original['fr_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Key Findings:**\n",
    "- Correlation between topological similarity (Wasserstein distance) and translation quality (BLEU)\n",
    "- H0 vs H1 contribution to the relationship\n",
    "- Binned analysis showing trend across similarity levels\n",
    "\n",
    "**Hypothesis Test:**\n",
    "Does lower Wasserstein distance (more topologically similar attention patterns) predict higher BLEU scores (better translation quality)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

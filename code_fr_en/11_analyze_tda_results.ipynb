{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze TDA Results\n",
    "\n",
    "Load and analyze persistent homology and Wasserstein distance results.\n",
    "\n",
    "**Change the configuration below to analyze different layer/filtering combinations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**Modify these variables to load different result files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Change these to analyze different results\n",
    "# ============================================================================\n",
    "\n",
    "LAYER = -1              # -1 for last layer, or 0-11 for specific layer\n",
    "FILTER_SPECIAL = True   # True to use filtered results, False for unfiltered\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "# Generate filename based on config\n",
    "layer_str = f\"layer{LAYER}\" if LAYER >= 0 else \"last_layer\"\n",
    "filter_str = \"filtered\" if FILTER_SPECIAL else \"unfiltered\"\n",
    "FILENAME = f\"tda_results_{layer_str}_{filter_str}.pkl\"\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Layer: {LAYER} ({'last layer' if LAYER == -1 else f'layer {LAYER}'})\")\n",
    "print(f\"  Filtered: {FILTER_SPECIAL}\")\n",
    "print(f\"  File: {FILENAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pickle\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport pandas as pd\nfrom scipy import stats\nimport warnings\n\n# Suppress warnings about infinite death times in persistence diagrams\nwarnings.filterwarnings('ignore', message='.*non-finite death times.*')\n\n# TDA visualization\nfrom persim import plot_diagrams\n\n# Set plotting style\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.figsize'] = (12, 6)\n\nprint(\"✓ Libraries imported\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load TDA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "data_path = Path(f\"../data/tda_results_fr_en/{FILENAME}\")\n",
    "\n",
    "print(f\"Loading results from {data_path}...\")\n",
    "print(f\"File size: {data_path.stat().st_size / (1024**2):.1f} MB\")\n",
    "print()\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Loaded {len(results)} sentence pairs\")\n",
    "print()\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "df = pd.DataFrame([{\n",
    "    'idx': r['idx'],\n",
    "    'en_text': r['en_text'],\n",
    "    'fr_text': r['fr_text'],\n",
    "    'wasserstein_distance': r['wasserstein_distance'],\n",
    "    'wasserstein_h0': r['wasserstein_h0'],\n",
    "    'wasserstein_h1': r['wasserstein_h1'],\n",
    "    'en_num_tokens': r['en_num_tokens'],\n",
    "    'fr_num_tokens': r['fr_num_tokens'],\n",
    "    'en_h0_features': r['en_h0_features'],\n",
    "    'en_h1_features': r['en_h1_features'],\n",
    "    'fr_h0_features': r['fr_h0_features'],\n",
    "    'fr_h1_features': r['fr_h1_features']\n",
    "} for r in results])\n",
    "\n",
    "print(\"DataFrame created:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "print(\"Wasserstein Distance (Total):\")\n",
    "print(f\"  Min:    {df['wasserstein_distance'].min():.6f}\")\n",
    "print(f\"  Max:    {df['wasserstein_distance'].max():.6f}\")\n",
    "print(f\"  Mean:   {df['wasserstein_distance'].mean():.6f}\")\n",
    "print(f\"  Median: {df['wasserstein_distance'].median():.6f}\")\n",
    "print(f\"  Std:    {df['wasserstein_distance'].std():.6f}\")\n",
    "print()\n",
    "\n",
    "print(\"Wasserstein Distance by Dimension:\")\n",
    "print(f\"  H0 - Mean: {df['wasserstein_h0'].mean():.6f}, Std: {df['wasserstein_h0'].std():.6f}\")\n",
    "print(f\"  H1 - Mean: {df['wasserstein_h1'].mean():.6f}, Std: {df['wasserstein_h1'].std():.6f}\")\n",
    "print()\n",
    "\n",
    "print(\"Token Counts:\")\n",
    "print(f\"  English - Mean: {df['en_num_tokens'].mean():.1f}, Range: [{df['en_num_tokens'].min()}, {df['en_num_tokens'].max()}]\")\n",
    "print(f\"  French  - Mean: {df['fr_num_tokens'].mean():.1f}, Range: [{df['fr_num_tokens'].min()}, {df['fr_num_tokens'].max()}]\")\n",
    "print()\n",
    "\n",
    "print(\"H0 Features (β₀ - Connected Components):\")\n",
    "print(f\"  English - Mean: {df['en_h0_features'].mean():.1f}, Max: {df['en_h0_features'].max()}\")\n",
    "print(f\"  French  - Mean: {df['fr_h0_features'].mean():.1f}, Max: {df['fr_h0_features'].max()}\")\n",
    "print()\n",
    "\n",
    "print(\"H1 Features (β₁ - Loops/Holes):\")\n",
    "print(f\"  English - Mean: {df['en_h1_features'].mean():.1f}, Max: {df['en_h1_features'].max()}\")\n",
    "print(f\"  French  - Mean: {df['fr_h1_features'].mean():.1f}, Max: {df['fr_h1_features'].max()}\")\n",
    "print(f\"  Pairs with H1 features: {(df['en_h1_features'] > 0).sum()} EN, {(df['fr_h1_features'] > 0).sum()} FR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Wasserstein Distance Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Total Wasserstein distance\n",
    "axes[0].hist(df['wasserstein_distance'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0].axvline(df['wasserstein_distance'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df[\"wasserstein_distance\"].mean():.4f}')\n",
    "axes[0].axvline(df['wasserstein_distance'].median(), color='green', linestyle='--', \n",
    "                label=f'Median: {df[\"wasserstein_distance\"].median():.4f}')\n",
    "axes[0].set_xlabel('Wasserstein Distance')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Total Wasserstein Distance\\n(Lower = More Topologically Similar)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# H0 component\n",
    "axes[1].hist(df['wasserstein_h0'], bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "axes[1].axvline(df['wasserstein_h0'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df[\"wasserstein_h0\"].mean():.4f}')\n",
    "axes[1].set_xlabel('Wasserstein Distance (H0)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('H0 Component (Connected Components)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# H1 component\n",
    "axes[2].hist(df['wasserstein_h1'], bins=50, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[2].axvline(df['wasserstein_h1'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df[\"wasserstein_h1\"].mean():.4f}')\n",
    "axes[2].set_xlabel('Wasserstein Distance (H1)')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('H1 Component (Loops/Holes)')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"H0 contributes {df['wasserstein_h0'].mean() / df['wasserstein_distance'].mean() * 100:.1f}% to total distance\")\n",
    "print(f\"H1 contributes {df['wasserstein_h1'].mean() / df['wasserstein_distance'].mean() * 100:.1f}% to total distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Topological Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# H0 feature counts\naxes[0, 0].hist(df['en_h0_features'], bins=30, alpha=0.5, color='blue', label='English', edgecolor='black')\naxes[0, 0].hist(df['fr_h0_features'], bins=30, alpha=0.5, color='green', label='French', edgecolor='black')\naxes[0, 0].set_xlabel('Number of H0 Features')\naxes[0, 0].set_ylabel('Frequency')\naxes[0, 0].set_title('H0 Feature Count Distribution (Connected Components)')\naxes[0, 0].legend()\naxes[0, 0].grid(alpha=0.3)\n\n# H1 feature counts\naxes[0, 1].hist(df['en_h1_features'], bins=range(0, max(df['en_h1_features'].max(), df['fr_h1_features'].max()) + 2), \n                alpha=0.5, color='blue', label='English', edgecolor='black', align='left')\naxes[0, 1].hist(df['fr_h1_features'], bins=range(0, max(df['en_h1_features'].max(), df['fr_h1_features'].max()) + 2), \n                alpha=0.5, color='green', label='French', edgecolor='black', align='left')\naxes[0, 1].set_xlabel('Number of H1 Features')\naxes[0, 1].set_ylabel('Frequency')\naxes[0, 1].set_title('H1 Feature Count Distribution (Loops/Holes)')\naxes[0, 1].legend()\naxes[0, 1].grid(alpha=0.3)\n\n# Token count distribution\naxes[1, 0].hist(df['en_num_tokens'], bins=30, alpha=0.5, color='blue', label='English', edgecolor='black')\naxes[1, 0].hist(df['fr_num_tokens'], bins=30, alpha=0.5, color='green', label='French', edgecolor='black')\naxes[1, 0].set_xlabel('Number of Tokens')\naxes[1, 0].set_ylabel('Frequency')\naxes[1, 0].set_title('Token Count Distribution')\naxes[1, 0].legend()\naxes[1, 0].grid(alpha=0.3)\n\n# Wasserstein vs token count\naxes[1, 1].scatter(df['en_num_tokens'], df['wasserstein_distance'], alpha=0.3, s=10, color='blue', label='English tokens')\naxes[1, 1].scatter(df['fr_num_tokens'], df['wasserstein_distance'], alpha=0.3, s=10, color='green', label='French tokens')\n\n# Best fit lines (LMSE / linear regression)\n# English\nen_slope, en_intercept, en_r, _, _ = stats.linregress(df['en_num_tokens'], df['wasserstein_distance'])\nen_fit_x = np.array([df['en_num_tokens'].min(), df['en_num_tokens'].max()])\nen_fit_y = en_slope * en_fit_x + en_intercept\naxes[1, 1].plot(en_fit_x, en_fit_y, color='blue', linewidth=2, alpha=0.8, label=f'EN fit (r={en_r:.3f})')\n\n# French\nfr_slope, fr_intercept, fr_r, _, _ = stats.linregress(df['fr_num_tokens'], df['wasserstein_distance'])\nfr_fit_x = np.array([df['fr_num_tokens'].min(), df['fr_num_tokens'].max()])\nfr_fit_y = fr_slope * fr_fit_x + fr_intercept\naxes[1, 1].plot(fr_fit_x, fr_fit_y, color='green', linewidth=2, alpha=0.8, label=f'FR fit (r={fr_r:.3f})')\n\naxes[1, 1].set_xlabel('Number of Tokens')\naxes[1, 1].set_ylabel('Wasserstein Distance')\naxes[1, 1].set_title('Wasserstein Distance vs Token Count')\naxes[1, 1].legend()\naxes[1, 1].grid(alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Most vs Least Topologically Similar Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Sort by Wasserstein distance\ndf_sorted = df.sort_values('wasserstein_distance')\n\nprint(\"=\" * 70)\nprint(\"MOST TOPOLOGICALLY SIMILAR PAIRS (Lowest Wasserstein Distance)\")\nprint(\"=\" * 70)\nfor i in range(5):\n    row = df_sorted.iloc[i]\n    print(f\"\\n[{i+1}] Pair {row['idx']}: W-dist = {row['wasserstein_distance']:.6f} (H0: {row['wasserstein_h0']:.4f}, H1: {row['wasserstein_h1']:.4f})\")\n    print(f\"    EN ({row['en_num_tokens']} tokens): {row['en_text']}\")\n    print(f\"    FR ({row['fr_num_tokens']} tokens): {row['fr_text']}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"LEAST TOPOLOGICALLY SIMILAR PAIRS (Highest Wasserstein Distance)\")\nprint(\"=\" * 70)\nfor i in range(5):\n    row = df_sorted.iloc[-(i+1)]\n    print(f\"\\n[{i+1}] Pair {row['idx']}: W-dist = {row['wasserstein_distance']:.6f} (H0: {row['wasserstein_h0']:.4f}, H1: {row['wasserstein_h1']:.4f})\")\n    print(f\"    EN ({row['en_num_tokens']} tokens): {row['en_text']}\")\n    print(f\"    FR ({row['fr_num_tokens']} tokens): {row['fr_text']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Persistence Diagrams for Extreme Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most similar pair\n",
    "most_similar_idx = df_sorted.iloc[0]['idx']\n",
    "most_similar = results[most_similar_idx]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plot_diagrams(most_similar['en_diagrams'], show=False)\n",
    "axes[0].set_title('English')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plot_diagrams(most_similar['fr_diagrams'], show=False)\n",
    "axes[1].set_title('French')\n",
    "\n",
    "fig.suptitle(f\"Most Topologically Similar Pair (W-dist: {most_similar['wasserstein_distance']:.6f})\\nEN: {most_similar['en_text'][:60]}...\\nFR: {most_similar['fr_text'][:60]}...\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least similar pair\n",
    "least_similar_idx = df_sorted.iloc[-1]['idx']\n",
    "least_similar = results[least_similar_idx]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plot_diagrams(least_similar['en_diagrams'], show=False)\n",
    "axes[0].set_title('English')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plot_diagrams(least_similar['fr_diagrams'], show=False)\n",
    "axes[1].set_title('French')\n",
    "\n",
    "fig.suptitle(f\"Least Topologically Similar Pair (W-dist: {least_similar['wasserstein_distance']:.6f})\\nEN: {least_similar['en_text'][:60]}...\\nFR: {least_similar['fr_text'][:60]}...\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlations\n",
    "print(\"Correlation Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Token count vs Wasserstein distance\n",
    "corr_en_tokens = df['en_num_tokens'].corr(df['wasserstein_distance'])\n",
    "corr_fr_tokens = df['fr_num_tokens'].corr(df['wasserstein_distance'])\n",
    "print(f\"Token count vs Wasserstein distance:\")\n",
    "print(f\"  English tokens: r = {corr_en_tokens:.4f}\")\n",
    "print(f\"  French tokens:  r = {corr_fr_tokens:.4f}\")\n",
    "print()\n",
    "\n",
    "# H0 features vs Wasserstein\n",
    "corr_en_h0 = df['en_h0_features'].corr(df['wasserstein_distance'])\n",
    "corr_fr_h0 = df['fr_h0_features'].corr(df['wasserstein_distance'])\n",
    "print(f\"H0 features vs Wasserstein distance:\")\n",
    "print(f\"  English H0: r = {corr_en_h0:.4f}\")\n",
    "print(f\"  French H0:  r = {corr_fr_h0:.4f}\")\n",
    "print()\n",
    "\n",
    "# Cross-language feature correlation\n",
    "corr_h0_cross = df['en_h0_features'].corr(df['fr_h0_features'])\n",
    "corr_h1_cross = df['en_h1_features'].corr(df['fr_h1_features'])\n",
    "print(f\"Cross-language feature correlation:\")\n",
    "print(f\"  H0 (EN vs FR): r = {corr_h0_cross:.4f}\")\n",
    "print(f\"  H1 (EN vs FR): r = {corr_h1_cross:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(f\"  - Cross-language H0 correlation of {corr_h0_cross:.2f} suggests {'high' if corr_h0_cross > 0.7 else 'moderate' if corr_h0_cross > 0.4 else 'low'} structural similarity\")\n",
    "print(f\"  - Mean Wasserstein distance: {df['wasserstein_distance'].mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
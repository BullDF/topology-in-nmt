{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Analyze TDA Results\n\nLoad and analyze persistent homology and Wasserstein distance results.\n\n**For Google Colab:**\n1. Mount Google Drive (run cell below)\n2. Set `ROOT_DIR` to your project folder path in code_fr_en\n\n**For local execution:** Skip the Google Drive cell and run from \"Verify Working Directory\"\n\n---\n\n**Note:** TDA analysis uses last encoder layer (layer 23/24) attention only."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (only needed for Google Colab)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # IMPORTANT: Set this to your code_fr_en directory path\n",
    "    # This should point to where THIS notebook is located\n",
    "    ROOT_DIR = \"/content/drive/MyDrive/UofT/CSC2517/term_paper/code_fr_en\"\n",
    "    \n",
    "    import os\n",
    "    os.chdir(ROOT_DIR)\n",
    "    print(f\"✓ Changed to: {os.getcwd()}\")\n",
    "except ImportError:\n",
    "    print(\"Not running on Colab, using local environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify working directory and required files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Check TDA results directory\n",
    "tda_dir = \"../data/tda_results_fr_en\"\n",
    "if os.path.exists(tda_dir):\n",
    "    print(f\"✓ TDA results directory exists: {tda_dir}\")\n",
    "    # List available result files\n",
    "    result_files = sorted(Path(tda_dir).glob(\"tda_results_*.pkl\"))\n",
    "    print(f\"  Found {len(result_files)} result file(s):\")\n",
    "    for f in result_files:\n",
    "        print(f\"    - {f.name} ({f.stat().st_size / (1024**2):.1f} MB)\")\n",
    "else:\n",
    "    print(f\"✗ TDA results directory NOT found: {tda_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Configuration\n\n**Modify this variable to load different result files:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# CONFIGURATION - Change this to analyze different results\n# ============================================================================\n\nFILTER_SPECIAL = True   # True to use filtered results, False for unfiltered\n\n# ============================================================================\n\n# Generate filename based on config\nfilter_str = \"filtered\" if FILTER_SPECIAL else \"unfiltered\"\nFILENAME = f\"tda_results_last_layer_{filter_str}.pkl\"\n\nprint(f\"Configuration:\")\nprint(f\"  Special tokens filtered: {FILTER_SPECIAL}\")\nprint(f\"  File: {FILENAME}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Install TDA libraries if not already installed\n!pip install ripser persim",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings about infinite death times in persistence diagrams\n",
    "warnings.filterwarnings('ignore', message='.*non-finite death times.*')\n",
    "\n",
    "# TDA visualization\n",
    "from persim import plot_diagrams\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load TDA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "data_path = Path(f\"../data/tda_results_fr_en/{FILENAME}\")\n",
    "\n",
    "print(f\"Loading results from {data_path}...\")\n",
    "print(f\"File size: {data_path.stat().st_size / (1024**2):.1f} MB\")\n",
    "print()\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Loaded {len(results)} sentence pairs\")\n",
    "print()\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "df = pd.DataFrame([{\n",
    "    'idx': r['idx'],\n",
    "    'en_text': r['en_text'],\n",
    "    'fr_text': r['fr_text'],\n",
    "    'wasserstein_distance': r['wasserstein_distance'],\n",
    "    'wasserstein_h0': r['wasserstein_h0'],\n",
    "    'wasserstein_h1': r['wasserstein_h1'],\n",
    "    'en_num_tokens': r['en_num_tokens'],\n",
    "    'fr_num_tokens': r['fr_num_tokens'],\n",
    "    'en_h0_features': r['en_h0_features'],\n",
    "    'en_h1_features': r['en_h1_features'],\n",
    "    'fr_h0_features': r['fr_h0_features'],\n",
    "    'fr_h1_features': r['fr_h1_features']\n",
    "} for r in results])\n",
    "\n",
    "print(\"DataFrame created:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 70)\nprint(\"SUMMARY STATISTICS\")\nprint(\"=\" * 70)\nprint()\n\nprint(\"Wasserstein Distance (Total):\")\nprint(f\"  Min:    {df['wasserstein_distance'].min():.6f}\")\nprint(f\"  Max:    {df['wasserstein_distance'].max():.6f}\")\nprint(f\"  Mean:   {df['wasserstein_distance'].mean():.6f}\")\nprint(f\"  Median: {df['wasserstein_distance'].median():.6f}\")\nprint(f\"  Std:    {df['wasserstein_distance'].std():.6f}\")\nprint()\n\nprint(\"Wasserstein Distance by Dimension:\")\nprint(f\"  H0 - Min: {df['wasserstein_h0'].min():.6f}, Max: {df['wasserstein_h0'].max():.6f}, Mean: {df['wasserstein_h0'].mean():.6f}, Median: {df['wasserstein_h0'].median():.6f}\")\nprint(f\"  H1 - Min: {df['wasserstein_h1'].min():.6f}, Max: {df['wasserstein_h1'].max():.6f}, Mean: {df['wasserstein_h1'].mean():.6f}, Median: {df['wasserstein_h1'].median():.6f}\")\nprint()\n\nprint(\"Token Counts:\")\nprint(f\"  English - Min: {df['en_num_tokens'].min()}, Max: {df['en_num_tokens'].max()}, Mean: {df['en_num_tokens'].mean():.1f}, Median: {df['en_num_tokens'].median():.1f}\")\nprint(f\"  French  - Min: {df['fr_num_tokens'].min()}, Max: {df['fr_num_tokens'].max()}, Mean: {df['fr_num_tokens'].mean():.1f}, Median: {df['fr_num_tokens'].median():.1f}\")\nprint()\n\nprint(\"H0 Features (β₀ - Connected Components):\")\nprint(f\"  English - Min: {df['en_h0_features'].min()}, Max: {df['en_h0_features'].max()}, Mean: {df['en_h0_features'].mean():.1f}, Median: {df['en_h0_features'].median():.1f}\")\nprint(f\"  French  - Min: {df['fr_h0_features'].min()}, Max: {df['fr_h0_features'].max()}, Mean: {df['fr_h0_features'].mean():.1f}, Median: {df['fr_h0_features'].median():.1f}\")\nprint()\n\nprint(\"H1 Features (β₁ - Loops/Holes):\")\nprint(f\"  English - Min: {df['en_h1_features'].min()}, Max: {df['en_h1_features'].max()}, Mean: {df['en_h1_features'].mean():.1f}, Median: {df['en_h1_features'].median():.1f}\")\nprint(f\"  French  - Min: {df['fr_h1_features'].min()}, Max: {df['fr_h1_features'].max()}, Mean: {df['fr_h1_features'].mean():.1f}, Median: {df['fr_h1_features'].median():.1f}\")\nprint(f\"  Pairs with H1 features: {(df['en_h1_features'] > 0).sum()} EN, {(df['fr_h1_features'] > 0).sum()} FR\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Wasserstein Distance Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Total Wasserstein distance\n",
    "axes[0].hist(df['wasserstein_distance'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0].axvline(df['wasserstein_distance'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df[\"wasserstein_distance\"].mean():.4f}')\n",
    "axes[0].axvline(df['wasserstein_distance'].median(), color='green', linestyle='--', \n",
    "                label=f'Median: {df[\"wasserstein_distance\"].median():.4f}')\n",
    "axes[0].set_xlabel('Wasserstein Distance')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Total Wasserstein Distance\\n(Lower = More Topologically Similar)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# H0 component\n",
    "axes[1].hist(df['wasserstein_h0'], bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "axes[1].axvline(df['wasserstein_h0'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df[\"wasserstein_h0\"].mean():.4f}')\n",
    "axes[1].set_xlabel('Wasserstein Distance (H0)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('H0 Component (Connected Components)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# H1 component\n",
    "axes[2].hist(df['wasserstein_h1'], bins=50, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[2].axvline(df['wasserstein_h1'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df[\"wasserstein_h1\"].mean():.4f}')\n",
    "axes[2].set_xlabel('Wasserstein Distance (H1)')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('H1 Component (Loops/Holes)')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"H0 contributes {df['wasserstein_h0'].mean() / df['wasserstein_distance'].mean() * 100:.1f}% to total distance\")\n",
    "print(f\"H1 contributes {df['wasserstein_h1'].mean() / df['wasserstein_distance'].mean() * 100:.1f}% to total distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Topological Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# H0 feature counts\n",
    "axes[0, 0].hist(df['en_h0_features'], bins=30, alpha=0.5, color='blue', label='English', edgecolor='black')\n",
    "axes[0, 0].hist(df['fr_h0_features'], bins=30, alpha=0.5, color='green', label='French', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Number of H0 Features')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('H0 Feature Count Distribution (Connected Components)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# H1 feature counts\n",
    "axes[0, 1].hist(df['en_h1_features'], bins=range(0, max(df['en_h1_features'].max(), df['fr_h1_features'].max()) + 2), \n",
    "                alpha=0.5, color='blue', label='English', edgecolor='black', align='left')\n",
    "axes[0, 1].hist(df['fr_h1_features'], bins=range(0, max(df['en_h1_features'].max(), df['fr_h1_features'].max()) + 2), \n",
    "                alpha=0.5, color='green', label='French', edgecolor='black', align='left')\n",
    "axes[0, 1].set_xlabel('Number of H1 Features')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('H1 Feature Count Distribution (Loops/Holes)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Token count distribution\n",
    "axes[1, 0].hist(df['en_num_tokens'], bins=30, alpha=0.5, color='blue', label='English', edgecolor='black')\n",
    "axes[1, 0].hist(df['fr_num_tokens'], bins=30, alpha=0.5, color='green', label='French', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Number of Tokens')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Token Count Distribution')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Wasserstein vs token count\n",
    "axes[1, 1].scatter(df['en_num_tokens'], df['wasserstein_distance'], alpha=0.3, s=10, color='blue', label='English tokens')\n",
    "axes[1, 1].scatter(df['fr_num_tokens'], df['wasserstein_distance'], alpha=0.3, s=10, color='green', label='French tokens')\n",
    "\n",
    "# Best fit lines (linear regression)\n",
    "# English\n",
    "en_slope, en_intercept, en_r, _, _ = stats.linregress(df['en_num_tokens'], df['wasserstein_distance'])\n",
    "en_fit_x = np.array([df['en_num_tokens'].min(), df['en_num_tokens'].max()])\n",
    "en_fit_y = en_slope * en_fit_x + en_intercept\n",
    "axes[1, 1].plot(en_fit_x, en_fit_y, color='blue', linewidth=2, alpha=0.8, label=f'EN fit (r={en_r:.3f})')\n",
    "\n",
    "# French\n",
    "fr_slope, fr_intercept, fr_r, _, _ = stats.linregress(df['fr_num_tokens'], df['wasserstein_distance'])\n",
    "fr_fit_x = np.array([df['fr_num_tokens'].min(), df['fr_num_tokens'].max()])\n",
    "fr_fit_y = fr_slope * fr_fit_x + fr_intercept\n",
    "axes[1, 1].plot(fr_fit_x, fr_fit_y, color='green', linewidth=2, alpha=0.8, label=f'FR fit (r={fr_r:.3f})')\n",
    "\n",
    "axes[1, 1].set_xlabel('Number of Tokens')\n",
    "axes[1, 1].set_ylabel('Wasserstein Distance')\n",
    "axes[1, 1].set_title('Wasserstein Distance vs Token Count')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Most vs Least Topologically Similar Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Wasserstein distance\n",
    "df_sorted = df.sort_values('wasserstein_distance')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MOST TOPOLOGICALLY SIMILAR PAIRS (Lowest Wasserstein Distance)\")\n",
    "print(\"=\" * 70)\n",
    "for i in range(5):\n",
    "    row = df_sorted.iloc[i]\n",
    "    print(f\"\\n[{i+1}] Pair {row['idx']}: W-dist = {row['wasserstein_distance']:.6f} (H0: {row['wasserstein_h0']:.4f}, H1: {row['wasserstein_h1']:.4f})\")\n",
    "    print(f\"    EN ({row['en_num_tokens']} tokens): {row['en_text']}\")\n",
    "    print(f\"    FR ({row['fr_num_tokens']} tokens): {row['fr_text']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LEAST TOPOLOGICALLY SIMILAR PAIRS (Highest Wasserstein Distance)\")\n",
    "print(\"=\" * 70)\n",
    "for i in range(5):\n",
    "    row = df_sorted.iloc[-(i+1)]\n",
    "    print(f\"\\n[{i+1}] Pair {row['idx']}: W-dist = {row['wasserstein_distance']:.6f} (H0: {row['wasserstein_h0']:.4f}, H1: {row['wasserstein_h1']:.4f})\")\n",
    "    print(f\"    EN ({row['en_num_tokens']} tokens): {row['en_text']}\")\n",
    "    print(f\"    FR ({row['fr_num_tokens']} tokens): {row['fr_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Persistence Diagrams for Extreme Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most similar pair\n",
    "most_similar_idx = df_sorted.iloc[0]['idx']\n",
    "most_similar = results[most_similar_idx]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plot_diagrams(most_similar['en_diagrams'], show=False)\n",
    "axes[0].set_title('English')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plot_diagrams(most_similar['fr_diagrams'], show=False)\n",
    "axes[1].set_title('French')\n",
    "\n",
    "fig.suptitle(f\"Most Topologically Similar Pair (W-dist: {most_similar['wasserstein_distance']:.6f})\\nEN: {most_similar['en_text'][:60]}...\\nFR: {most_similar['fr_text'][:60]}...\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least similar pair\n",
    "least_similar_idx = df_sorted.iloc[-1]['idx']\n",
    "least_similar = results[least_similar_idx]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plot_diagrams(least_similar['en_diagrams'], show=False)\n",
    "axes[0].set_title('English')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plot_diagrams(least_similar['fr_diagrams'], show=False)\n",
    "axes[1].set_title('French')\n",
    "\n",
    "fig.suptitle(f\"Least Topologically Similar Pair (W-dist: {least_similar['wasserstein_distance']:.6f})\\nEN: {least_similar['en_text'][:60]}...\\nFR: {least_similar['fr_text'][:60]}...\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlations\n",
    "print(\"Correlation Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Token count vs Wasserstein distance\n",
    "corr_en_tokens = df['en_num_tokens'].corr(df['wasserstein_distance'])\n",
    "corr_fr_tokens = df['fr_num_tokens'].corr(df['wasserstein_distance'])\n",
    "print(f\"Token count vs Wasserstein distance:\")\n",
    "print(f\"  English tokens: r = {corr_en_tokens:.4f}\")\n",
    "print(f\"  French tokens:  r = {corr_fr_tokens:.4f}\")\n",
    "print()\n",
    "\n",
    "# H0 features vs Wasserstein\n",
    "corr_en_h0 = df['en_h0_features'].corr(df['wasserstein_distance'])\n",
    "corr_fr_h0 = df['fr_h0_features'].corr(df['wasserstein_distance'])\n",
    "print(f\"H0 features vs Wasserstein distance:\")\n",
    "print(f\"  English H0: r = {corr_en_h0:.4f}\")\n",
    "print(f\"  French H0:  r = {corr_fr_h0:.4f}\")\n",
    "print()\n",
    "\n",
    "# Cross-language feature correlation\n",
    "corr_h0_cross = df['en_h0_features'].corr(df['fr_h0_features'])\n",
    "corr_h1_cross = df['en_h1_features'].corr(df['fr_h1_features'])\n",
    "print(f\"Cross-language feature correlation:\")\n",
    "print(f\"  H0 (EN vs FR): r = {corr_h0_cross:.4f}\")\n",
    "print(f\"  H1 (EN vs FR): r = {corr_h1_cross:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(f\"  - Cross-language H0 correlation of {corr_h0_cross:.2f} suggests {'high' if corr_h0_cross > 0.7 else 'moderate' if corr_h0_cross > 0.4 else 'low'} structural similarity\")\n",
    "print(f\"  - Mean Wasserstein distance: {df['wasserstein_distance'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ **TDA Results Analysis Complete!**\n",
    "\n",
    "**What we analyzed:**\n",
    "- Wasserstein distance distributions (total, H0, H1)\n",
    "- Topological feature counts (β₀, β₁)\n",
    "- Correlation between token count and topological similarity\n",
    "- Cross-language structural similarity\n",
    "- Most/least topologically similar pairs\n",
    "\n",
    "**Next steps:**\n",
    "1. Compute BLEU scores for translation quality (notebook 12-13)\n",
    "2. Correlate topological similarity with translation quality (notebook 14)\n",
    "3. Statistical significance testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
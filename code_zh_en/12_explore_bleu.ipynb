{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore BLEU Score Computation\n",
    "\n",
    "Compute BLEU scores for translation quality assessment.\n",
    "\n",
    "We have:\n",
    "- `en_translation`: Generated Chinese (EN → ZH)\n",
    "- `zh_translation`: Generated English (ZH → EN)\n",
    "- `zh_text`: Reference Chinese\n",
    "- `en_text`: Reference English\n",
    "\n",
    "We'll compute:\n",
    "- **EN→ZH BLEU**: Compare `en_translation` with `zh_text`\n",
    "- **ZH→EN BLEU**: Compare `zh_translation` with `en_text`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install sacrebleu if needed (standard BLEU implementation)\n",
    "# !pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sacrebleu import sentence_bleu\n",
    "\n",
    "# Configure matplotlib for Chinese font support\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load TDA Results\n",
    "\n",
    "Load results that contain both translations and original texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TDA results (contains translations)\n",
    "data_path = Path(\"../data/tda_results_zh_en/tda_results_last_layer_filtered.pkl\")\n",
    "\n",
    "print(f\"Loading data from {data_path}...\")\n",
    "with open(data_path, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Loaded {len(results)} sentence pairs\")\n",
    "print()\n",
    "\n",
    "# Examine first result\n",
    "print(\"Data structure:\")\n",
    "print(f\"Keys: {list(results[0].keys())}\")\n",
    "print()\n",
    "print(\"Sample:\")\n",
    "print(f\"EN text:         {results[0]['en_text']}\")\n",
    "print(f\"ZH text:         {results[0]['zh_text']}\")\n",
    "print(f\"EN→ZH (generated): {results[0]['en_translation']}\")\n",
    "print(f\"ZH→EN (generated): {results[0]['zh_translation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute BLEU Scores for Sample Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu_scores(en_text, zh_text, en_translation, zh_translation):\n",
    "    \"\"\"\n",
    "    Compute BLEU scores for both translation directions.\n",
    "    \n",
    "    Args:\n",
    "        en_text: Original English text (reference for ZH→EN)\n",
    "        zh_text: Original Chinese text (reference for EN→ZH)\n",
    "        en_translation: Generated Chinese from English (hypothesis for EN→ZH)\n",
    "        zh_translation: Generated English from Chinese (hypothesis for ZH→EN)\n",
    "    \n",
    "    Returns:\n",
    "        dict with BLEU scores\n",
    "    \"\"\"\n",
    "    # EN→ZH: Compare generated Chinese with reference Chinese\n",
    "    bleu_en_zh = sentence_bleu(en_translation, [zh_text]).score\n",
    "    \n",
    "    # ZH→EN: Compare generated English with reference English\n",
    "    bleu_zh_en = sentence_bleu(zh_translation, [en_text]).score\n",
    "    \n",
    "    # Average BLEU\n",
    "    bleu_avg = (bleu_en_zh + bleu_zh_en) / 2\n",
    "    \n",
    "    return {\n",
    "        'bleu_en_zh': bleu_en_zh,\n",
    "        'bleu_zh_en': bleu_zh_en,\n",
    "        'bleu_avg': bleu_avg\n",
    "    }\n",
    "\n",
    "print(\"✓ Function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on first 10 examples\n",
    "print(\"Testing BLEU computation on first 10 examples:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(10):\n",
    "    example = results[i]\n",
    "    scores = compute_bleu_scores(\n",
    "        en_text=example['en_text'],\n",
    "        zh_text=example['zh_text'],\n",
    "        en_translation=example['en_translation'],\n",
    "        zh_translation=example['zh_translation']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n[{i}] EN→ZH: {scores['bleu_en_zh']:.2f}, ZH→EN: {scores['bleu_zh_en']:.2f}, Avg: {scores['bleu_avg']:.2f}\")\n",
    "    print(f\"    EN: {example['en_text'][:70]}...\")\n",
    "    print(f\"    ZH: {example['zh_text'][:70]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute BLEU for All Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute BLEU scores for all examples\n",
    "print(f\"Computing BLEU scores for {len(results)} sentence pairs...\")\n",
    "\n",
    "bleu_results = []\n",
    "for i, example in enumerate(results):\n",
    "    scores = compute_bleu_scores(\n",
    "        en_text=example['en_text'],\n",
    "        zh_text=example['zh_text'],\n",
    "        en_translation=example['en_translation'],\n",
    "        zh_translation=example['zh_translation']\n",
    "    )\n",
    "    \n",
    "    bleu_results.append({\n",
    "        'idx': i,\n",
    "        **scores\n",
    "    })\n",
    "    \n",
    "    if (i + 1) % 500 == 0:\n",
    "        print(f\"  Processed {i + 1}/{len(results)}\")\n",
    "\n",
    "print(f\"✓ Computed BLEU scores for all {len(bleu_results)} pairs\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_bleu = pd.DataFrame(bleu_results)\n",
    "print(\"\\nDataFrame:\")\n",
    "print(df_bleu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"BLEU SCORE STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "print(\"EN→ZH BLEU:\")\n",
    "print(f\"  Min:    {df_bleu['bleu_en_zh'].min():.2f}\")\n",
    "print(f\"  Max:    {df_bleu['bleu_en_zh'].max():.2f}\")\n",
    "print(f\"  Mean:   {df_bleu['bleu_en_zh'].mean():.2f}\")\n",
    "print(f\"  Median: {df_bleu['bleu_en_zh'].median():.2f}\")\n",
    "print(f\"  Std:    {df_bleu['bleu_en_zh'].std():.2f}\")\n",
    "print()\n",
    "\n",
    "print(\"ZH→EN BLEU:\")\n",
    "print(f\"  Min:    {df_bleu['bleu_zh_en'].min():.2f}\")\n",
    "print(f\"  Max:    {df_bleu['bleu_zh_en'].max():.2f}\")\n",
    "print(f\"  Mean:   {df_bleu['bleu_zh_en'].mean():.2f}\")\n",
    "print(f\"  Median: {df_bleu['bleu_zh_en'].median():.2f}\")\n",
    "print(f\"  Std:    {df_bleu['bleu_zh_en'].std():.2f}\")\n",
    "print()\n",
    "\n",
    "print(\"Average BLEU:\")\n",
    "print(f\"  Min:    {df_bleu['bleu_avg'].min():.2f}\")\n",
    "print(f\"  Max:    {df_bleu['bleu_avg'].max():.2f}\")\n",
    "print(f\"  Mean:   {df_bleu['bleu_avg'].mean():.2f}\")\n",
    "print(f\"  Median: {df_bleu['bleu_avg'].median():.2f}\")\n",
    "print(f\"  Std:    {df_bleu['bleu_avg'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize BLEU Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# EN→ZH BLEU\n",
    "axes[0].hist(df_bleu['bleu_en_zh'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0].axvline(df_bleu['bleu_en_zh'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df_bleu[\"bleu_en_zh\"].mean():.2f}')\n",
    "axes[0].set_xlabel('BLEU Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('EN→ZH BLEU Distribution')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# ZH→EN BLEU\n",
    "axes[1].hist(df_bleu['bleu_zh_en'], bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1].axvline(df_bleu['bleu_zh_en'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df_bleu[\"bleu_zh_en\"].mean():.2f}')\n",
    "axes[1].set_xlabel('BLEU Score')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('ZH→EN BLEU Distribution')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Average BLEU\n",
    "axes[2].hist(df_bleu['bleu_avg'], bins=50, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[2].axvline(df_bleu['bleu_avg'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df_bleu[\"bleu_avg\"].mean():.2f}')\n",
    "axes[2].set_xlabel('BLEU Score')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('Average BLEU Distribution')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best and Worst Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by average BLEU\n",
    "df_bleu_sorted = df_bleu.sort_values('bleu_avg', ascending=False)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BEST TRANSLATIONS (Highest BLEU)\")\n",
    "print(\"=\"*70)\n",
    "for i in range(5):\n",
    "    idx = int(df_bleu_sorted.iloc[i]['idx'])\n",
    "    example = results[idx]\n",
    "    scores = df_bleu_sorted.iloc[i]\n",
    "    \n",
    "    print(f\"\\n[{i+1}] Pair {idx}: Avg BLEU = {scores['bleu_avg']:.2f} (EN→ZH: {scores['bleu_en_zh']:.2f}, ZH→EN: {scores['bleu_zh_en']:.2f})\")\n",
    "    print(f\"    EN: {example['en_text']}\")\n",
    "    print(f\"    ZH: {example['zh_text']}\")\n",
    "    print(f\"    Generated ZH: {example['en_translation']}\")\n",
    "    print(f\"    Generated EN: {example['zh_translation']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WORST TRANSLATIONS (Lowest BLEU)\")\n",
    "print(\"=\"*70)\n",
    "for i in range(5):\n",
    "    idx = int(df_bleu_sorted.iloc[-(i+1)]['idx'])\n",
    "    example = results[idx]\n",
    "    scores = df_bleu_sorted.iloc[-(i+1)]\n",
    "    \n",
    "    print(f\"\\n[{i+1}] Pair {idx}: Avg BLEU = {scores['bleu_avg']:.2f} (EN→ZH: {scores['bleu_en_zh']:.2f}, ZH→EN: {scores['bleu_zh_en']:.2f})\")\n",
    "    print(f\"    EN: {example['en_text']}\")\n",
    "    print(f\"    ZH: {example['zh_text']}\")\n",
    "    print(f\"    Generated ZH: {example['en_translation']}\")\n",
    "    print(f\"    Generated EN: {example['zh_translation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation Between EN→ZH and ZH→EN BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(df_bleu['bleu_en_zh'], df_bleu['bleu_zh_en'], alpha=0.3, s=10)\n",
    "plt.xlabel('EN→ZH BLEU')\n",
    "plt.ylabel('ZH→EN BLEU')\n",
    "plt.title('Correlation Between Translation Directions')\n",
    "plt.plot([0, 100], [0, 100], 'r--', alpha=0.5, label='y=x')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute correlation\n",
    "corr = df_bleu['bleu_en_zh'].corr(df_bleu['bleu_zh_en'])\n",
    "print(f\"Correlation between EN→ZH and ZH→EN BLEU: r = {corr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

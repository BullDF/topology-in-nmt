{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze TDA Results\n",
    "\n",
    "Load and analyze persistent homology and Wasserstein distance results.\n",
    "\n",
    "**For Google Colab:**\n",
    "1. Mount Google Drive (run cell below)\n",
    "2. Set `ROOT_DIR` to your project folder path in code_zh_en\n",
    "\n",
    "**For local execution:** Skip the Google Drive cell and run from \"Verify Working Directory\"\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** TDA analysis uses last encoder layer (layer 23/24) attention only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (only needed for Google Colab)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # IMPORTANT: Set this to your code_zh_en directory path\n",
    "    # This should point to where THIS notebook is located\n",
    "    ROOT_DIR = \"/content/drive/MyDrive/UofT/CSC2517/term_paper/code_zh_en\"\n",
    "    \n",
    "    import os\n",
    "    os.chdir(ROOT_DIR)\n",
    "    print(f\"✓ Changed to: {os.getcwd()}\")\n",
    "except ImportError:\n",
    "    print(\"Not running on Colab, using local environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify working directory and required files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Check TDA results directory\n",
    "tda_dir = \"../data/tda_results_zh_en\"\n",
    "if os.path.exists(tda_dir):\n",
    "    print(f\"✓ TDA results directory exists: {tda_dir}\")\n",
    "    # List available result files\n",
    "    result_files = sorted(Path(tda_dir).glob(\"tda_results_*.pkl\"))\n",
    "    print(f\"  Found {len(result_files)} result file(s):\")\n",
    "    for f in result_files:\n",
    "        print(f\"    - {f.name} ({f.stat().st_size / (1024**2):.1f} MB)\")\n",
    "else:\n",
    "    print(f\"✗ TDA results directory NOT found: {tda_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**Modify this variable to load different result files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Change this to analyze different results\n",
    "# ============================================================================\n",
    "\n",
    "FILTER_SPECIAL = True   # True to use filtered results, False for unfiltered\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "# Generate filename based on config\n",
    "filter_str = \"filtered\" if FILTER_SPECIAL else \"unfiltered\"\n",
    "FILENAME = f\"tda_results_last_layer_{filter_str}.pkl\"\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Special tokens filtered: {FILTER_SPECIAL}\")\n",
    "print(f\"  File: {FILENAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TDA libraries if not already installed\n",
    "!pip install ripser persim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import matplotlib\n",
    "\n",
    "# Configure matplotlib for Chinese font support\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Suppress warnings about infinite death times in persistence diagrams\n",
    "warnings.filterwarnings('ignore', message='.*non-finite death times.*')\n",
    "\n",
    "# TDA visualization\n",
    "from persim import plot_diagrams\n",
    "\n",
    "# Wrapper for plot_diagrams to apply font settings\n",
    "def plot_diagrams_with_font(diagrams, show=True, **kwargs):\n",
    "    with matplotlib.rc_context({'font.sans-serif': ['Arial Unicode MS'],\n",
    "                                 'axes.unicode_minus': False}):\n",
    "        plot_diagrams(diagrams, show=show, **kwargs)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load TDA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "data_path = Path(f\"../data/tda_results_zh_en/{FILENAME}\")\n",
    "\n",
    "print(f\"Loading results from {data_path}...\")\n",
    "print(f\"File size: {data_path.stat().st_size / (1024**2):.1f} MB\")\n",
    "print()\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Loaded {len(results)} sentence pairs\")\n",
    "print()\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "df = pd.DataFrame([{\n",
    "    'idx': r['idx'],\n",
    "    'en_text': r['en_text'],\n",
    "    'zh_text': r['zh_text'],\n",
    "    'wasserstein_distance': r['wasserstein_distance'],\n",
    "    'wasserstein_h0': r['wasserstein_h0'],\n",
    "    'wasserstein_h1': r['wasserstein_h1'],\n",
    "    'en_num_tokens': r['en_num_tokens'],\n",
    "    'zh_num_tokens': r['zh_num_tokens'],\n",
    "    'en_h0_features': r['en_h0_features'],\n",
    "    'en_h1_features': r['en_h1_features'],\n",
    "    'zh_h0_features': r['zh_h0_features'],\n",
    "    'zh_h1_features': r['zh_h1_features']\n",
    "} for r in results])\n",
    "\n",
    "print(\"DataFrame created:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "print(\"Wasserstein Distance (Total):\")\n",
    "print(f\"  Min:    {df['wasserstein_distance'].min():.6f}\")\n",
    "print(f\"  Max:    {df['wasserstein_distance'].max():.6f}\")\n",
    "print(f\"  Mean:   {df['wasserstein_distance'].mean():.6f}\")\n",
    "print(f\"  Median: {df['wasserstein_distance'].median():.6f}\")\n",
    "print(f\"  Std:    {df['wasserstein_distance'].std():.6f}\")\n",
    "print()\n",
    "\n",
    "print(\"Wasserstein Distance by Dimension:\")\n",
    "print(f\"  H0 - Mean: {df['wasserstein_h0'].mean():.6f}, Std: {df['wasserstein_h0'].std():.6f}\")\n",
    "print(f\"  H1 - Mean: {df['wasserstein_h1'].mean():.6f}, Std: {df['wasserstein_h1'].std():.6f}\")\n",
    "print()\n",
    "\n",
    "print(\"Token Counts:\")\n",
    "print(f\"  English - Mean: {df['en_num_tokens'].mean():.1f}, Range: [{df['en_num_tokens'].min()}, {df['en_num_tokens'].max()}]\")\n",
    "print(f\"  Chinese - Mean: {df['zh_num_tokens'].mean():.1f}, Range: [{df['zh_num_tokens'].min()}, {df['zh_num_tokens'].max()}]\")\n",
    "print()\n",
    "\n",
    "print(\"H0 Features (β₀ - Connected Components):\")\n",
    "print(f\"  English - Mean: {df['en_h0_features'].mean():.1f}, Max: {df['en_h0_features'].max()}\")\n",
    "print(f\"  Chinese - Mean: {df['zh_h0_features'].mean():.1f}, Max: {df['zh_h0_features'].max()}\")\n",
    "print()\n",
    "\n",
    "print(\"H1 Features (β₁ - Loops/Holes):\")\n",
    "print(f\"  English - Mean: {df['en_h1_features'].mean():.1f}, Max: {df['en_h1_features'].max()}\")\n",
    "print(f\"  Chinese - Mean: {df['zh_h1_features'].mean():.1f}, Max: {df['zh_h1_features'].max()}\")\n",
    "print(f\"  Pairs with H1 features: {(df['en_h1_features'] > 0).sum()} EN, {(df['zh_h1_features'] > 0).sum()} ZH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Wasserstein Distance Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Total Wasserstein distance\n",
    "axes[0].hist(df['wasserstein_distance'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0].axvline(df['wasserstein_distance'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df[\"wasserstein_distance\"].mean():.4f}')\n",
    "axes[0].axvline(df['wasserstein_distance'].median(), color='green', linestyle='--', \n",
    "                label=f'Median: {df[\"wasserstein_distance\"].median():.4f}')\n",
    "axes[0].set_xlabel('Wasserstein Distance')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Total Wasserstein Distance\\n(Lower = More Topologically Similar)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# H0 component\n",
    "axes[1].hist(df['wasserstein_h0'], bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "axes[1].axvline(df['wasserstein_h0'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df[\"wasserstein_h0\"].mean():.4f}')\n",
    "axes[1].set_xlabel('Wasserstein Distance (H0)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('H0 Component (Connected Components)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# H1 component\n",
    "axes[2].hist(df['wasserstein_h1'], bins=50, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[2].axvline(df['wasserstein_h1'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df[\"wasserstein_h1\"].mean():.4f}')\n",
    "axes[2].set_xlabel('Wasserstein Distance (H1)')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('H1 Component (Loops/Holes)')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"H0 contributes {df['wasserstein_h0'].mean() / df['wasserstein_distance'].mean() * 100:.1f}% to total distance\")\n",
    "print(f\"H1 contributes {df['wasserstein_h1'].mean() / df['wasserstein_distance'].mean() * 100:.1f}% to total distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Topological Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# H0 feature counts\n",
    "axes[0, 0].hist(df['en_h0_features'], bins=30, alpha=0.5, color='blue', label='English', edgecolor='black')\n",
    "axes[0, 0].hist(df['zh_h0_features'], bins=30, alpha=0.5, color='green', label='Chinese', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Number of H0 Features')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('H0 Feature Count Distribution (Connected Components)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# H1 feature counts\n",
    "axes[0, 1].hist(df['en_h1_features'], bins=range(0, max(df['en_h1_features'].max(), df['zh_h1_features'].max()) + 2), \n",
    "                alpha=0.5, color='blue', label='English', edgecolor='black', align='left')\n",
    "axes[0, 1].hist(df['zh_h1_features'], bins=range(0, max(df['en_h1_features'].max(), df['zh_h1_features'].max()) + 2), \n",
    "                alpha=0.5, color='green', label='Chinese', edgecolor='black', align='left')\n",
    "axes[0, 1].set_xlabel('Number of H1 Features')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('H1 Feature Count Distribution (Loops/Holes)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Token count distribution\n",
    "axes[1, 0].hist(df['en_num_tokens'], bins=30, alpha=0.5, color='blue', label='English', edgecolor='black')\n",
    "axes[1, 0].hist(df['zh_num_tokens'], bins=30, alpha=0.5, color='green', label='Chinese', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Number of Tokens')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Token Count Distribution')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Wasserstein vs token count\n",
    "axes[1, 1].scatter(df['en_num_tokens'], df['wasserstein_distance'], alpha=0.3, s=10, color='blue', label='English tokens')\n",
    "axes[1, 1].scatter(df['zh_num_tokens'], df['wasserstein_distance'], alpha=0.3, s=10, color='green', label='Chinese tokens')\n",
    "\n",
    "# Best fit lines (linear regression)\n",
    "# English\n",
    "en_slope, en_intercept, en_r, _, _ = stats.linregress(df['en_num_tokens'], df['wasserstein_distance'])\n",
    "en_fit_x = np.array([df['en_num_tokens'].min(), df['en_num_tokens'].max()])\n",
    "en_fit_y = en_slope * en_fit_x + en_intercept\n",
    "axes[1, 1].plot(en_fit_x, en_fit_y, color='blue', linewidth=2, alpha=0.8, label=f'EN fit (r={en_r:.3f})')\n",
    "\n",
    "# Chinese\n",
    "zh_slope, zh_intercept, zh_r, _, _ = stats.linregress(df['zh_num_tokens'], df['wasserstein_distance'])\n",
    "zh_fit_x = np.array([df['zh_num_tokens'].min(), df['zh_num_tokens'].max()])\n",
    "zh_fit_y = zh_slope * zh_fit_x + zh_intercept\n",
    "axes[1, 1].plot(zh_fit_x, zh_fit_y, color='green', linewidth=2, alpha=0.8, label=f'ZH fit (r={zh_r:.3f})')\n",
    "\n",
    "axes[1, 1].set_xlabel('Number of Tokens')\n",
    "axes[1, 1].set_ylabel('Wasserstein Distance')\n",
    "axes[1, 1].set_title('Wasserstein Distance vs Token Count')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Most vs Least Topologically Similar Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Wasserstein distance\n",
    "df_sorted = df.sort_values('wasserstein_distance')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MOST TOPOLOGICALLY SIMILAR PAIRS (Lowest Wasserstein Distance)\")\n",
    "print(\"=\" * 70)\n",
    "for i in range(5):\n",
    "    row = df_sorted.iloc[i]\n",
    "    print(f\"\\n[{i+1}] Pair {row['idx']}: W-dist = {row['wasserstein_distance']:.6f} (H0: {row['wasserstein_h0']:.4f}, H1: {row['wasserstein_h1']:.4f})\")\n",
    "    print(f\"    EN ({row['en_num_tokens']} tokens): {row['en_text']}\")\n",
    "    print(f\"    ZH ({row['zh_num_tokens']} tokens): {row['zh_text']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LEAST TOPOLOGICALLY SIMILAR PAIRS (Highest Wasserstein Distance)\")\n",
    "print(\"=\" * 70)\n",
    "for i in range(5):\n",
    "    row = df_sorted.iloc[-(i+1)]\n",
    "    print(f\"\\n[{i+1}] Pair {row['idx']}: W-dist = {row['wasserstein_distance']:.6f} (H0: {row['wasserstein_h0']:.4f}, H1: {row['wasserstein_h1']:.4f})\")\n",
    "    print(f\"    EN ({row['en_num_tokens']} tokens): {row['en_text']}\")\n",
    "    print(f\"    ZH ({row['zh_num_tokens']} tokens): {row['zh_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Persistence Diagrams for Extreme Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most similar pair\n",
    "most_similar_idx = df_sorted.iloc[0]['idx']\n",
    "most_similar = results[most_similar_idx]\n",
    "\n",
    "with matplotlib.rc_context({'font.sans-serif': ['Arial Unicode MS'],\n",
    "                             'axes.unicode_minus': False}):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    plt.sca(axes[0])\n",
    "    plot_diagrams(most_similar['en_diagrams'], show=False)\n",
    "    axes[0].set_title('English')\n",
    "\n",
    "    plt.sca(axes[1])\n",
    "    plot_diagrams(most_similar['zh_diagrams'], show=False)\n",
    "    axes[1].set_title('Chinese')\n",
    "\n",
    "    # Use explicit font properties for suptitle\n",
    "    from matplotlib.font_manager import FontProperties\n",
    "    font_prop = FontProperties(family='Arial Unicode MS')\n",
    "    fig.suptitle(f\"Most Topologically Similar Pair (W-dist: {most_similar['wasserstein_distance']:.6f})\\nEN: {most_similar['en_text'][:60]}...\\nZH: {most_similar['zh_text'][:60]}...\", \n",
    "                 fontsize=10, fontproperties=font_prop)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least similar pair\n",
    "least_similar_idx = df_sorted.iloc[-1]['idx']\n",
    "least_similar = results[least_similar_idx]\n",
    "\n",
    "with matplotlib.rc_context({'font.sans-serif': ['Arial Unicode MS'],\n",
    "                             'axes.unicode_minus': False}):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    plt.sca(axes[0])\n",
    "    plot_diagrams(least_similar['en_diagrams'], show=False)\n",
    "    axes[0].set_title('English')\n",
    "\n",
    "    plt.sca(axes[1])\n",
    "    plot_diagrams(least_similar['zh_diagrams'], show=False)\n",
    "    axes[1].set_title('Chinese')\n",
    "\n",
    "    # Use explicit font properties for suptitle\n",
    "    from matplotlib.font_manager import FontProperties\n",
    "    font_prop = FontProperties(family='Arial Unicode MS')\n",
    "    fig.suptitle(f\"Least Topologically Similar Pair (W-dist: {least_similar['wasserstein_distance']:.6f})\\nEN: {least_similar['en_text'][:60]}...\\nZH: {least_similar['zh_text'][:60]}...\", \n",
    "                 fontsize=10, fontproperties=font_prop)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlations\n",
    "print(\"Correlation Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Token count vs Wasserstein distance\n",
    "corr_en_tokens = df['en_num_tokens'].corr(df['wasserstein_distance'])\n",
    "corr_zh_tokens = df['zh_num_tokens'].corr(df['wasserstein_distance'])\n",
    "print(f\"Token count vs Wasserstein distance:\")\n",
    "print(f\"  English tokens: r = {corr_en_tokens:.4f}\")\n",
    "print(f\"  Chinese tokens: r = {corr_zh_tokens:.4f}\")\n",
    "print()\n",
    "\n",
    "# H0 features vs Wasserstein\n",
    "corr_en_h0 = df['en_h0_features'].corr(df['wasserstein_distance'])\n",
    "corr_zh_h0 = df['zh_h0_features'].corr(df['wasserstein_distance'])\n",
    "print(f\"H0 features vs Wasserstein distance:\")\n",
    "print(f\"  English H0: r = {corr_en_h0:.4f}\")\n",
    "print(f\"  Chinese H0: r = {corr_zh_h0:.4f}\")\n",
    "print()\n",
    "\n",
    "# Cross-language feature correlation\n",
    "corr_h0_cross = df['en_h0_features'].corr(df['zh_h0_features'])\n",
    "corr_h1_cross = df['en_h1_features'].corr(df['zh_h1_features'])\n",
    "print(f\"Cross-language feature correlation:\")\n",
    "print(f\"  H0 (EN vs ZH): r = {corr_h0_cross:.4f}\")\n",
    "print(f\"  H1 (EN vs ZH): r = {corr_h1_cross:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(f\"  - Cross-language H0 correlation of {corr_h0_cross:.2f} suggests {'high' if corr_h0_cross > 0.7 else 'moderate' if corr_h0_cross > 0.4 else 'low'} structural similarity\")\n",
    "print(f\"  - Mean Wasserstein distance: {df['wasserstein_distance'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ **TDA Results Analysis Complete!**\n",
    "\n",
    "**What we analyzed:**\n",
    "- Wasserstein distance distributions (total, H0, H1)\n",
    "- Topological feature counts (β₀, β₁)\n",
    "- Correlation between token count and topological similarity\n",
    "- Cross-language structural similarity\n",
    "- Most/least topologically similar pairs\n",
    "\n",
    "**Next steps:**\n",
    "1. Compute BLEU scores for translation quality (notebook 12-13)\n",
    "2. Correlate topological similarity with translation quality (notebook 14)\n",
    "3. Statistical significance testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
